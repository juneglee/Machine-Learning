{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07deb801",
   "metadata": {},
   "source": [
    "### 데이터 (입력 x, 정답 t)에 대한 Linear Regression (Simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d01cc",
   "metadata": {},
   "source": [
    "오차를 계산하기 위해서는 training data의 모든 입력 x에 대한 각각의 y = Wx + b 계산 해야 함 \n",
    "=> 이때, 입력 x, 정답 t, 가중치 W 모두 행렬로 나타낸 후에 행렬 곱 (dot product)을 이용하면 \n",
    "계산 값 y 또한 행렬로 표시되어 모든 입력 데이터에 대해 한번에 쉽게 계산되는 것을 알 수 있다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f437e2d",
   "metadata": {},
   "source": [
    "##### 학습 데이터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b42c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (5, 1) , t_data.shape =  (5, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1, 2, 3, 4, 5]).reshape(5,1)\n",
    "t_data = np.array([2, 3, 4, 5, 6]).reshape(5,1) \n",
    "\n",
    "# raw_data = [ [1, 2], [2, 3], [3, 4], [4, 5], [5, 6] ]\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06ceb2",
   "metadata": {},
   "source": [
    "##### 임의의 직선  y = Wx + b 정의  (임의이 값으로 가중치 W, 바이어스 b 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "881d5f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.95595834]] , W.shape =  (1, 1) , b =  [0.60628513] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)  \n",
    "b = np.random.rand(1)  \n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206fb84",
   "metadata": {},
   "source": [
    "##### 손실 함수 E(w, b) 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1e8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W) + b\n",
    "    \n",
    "    return (np.sum((t - y)**2))/ (len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512be72",
   "metadata": {},
   "source": [
    "#### 수치 미분 (numerical_derivative) 및 utility 함수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2deb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52ac0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    y = np.dot(x,W) + b\n",
    "    \n",
    "    return (np.sum((t - y)**2))/ (len(x))\n",
    "\n",
    "# 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy type\n",
    "def predict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e625a8",
   "metadata": {},
   "source": [
    "##### 학습률 (Learning rate) 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5022ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  0.2803868722332239 Initial W =  [[0.95595834]] \n",
      " , b =  [0.60628513]\n",
      "step =  0 error value =  0.17444098503004232 W =  [[0.9892704]] , b =  [0.6148032]\n",
      "step =  400 error value =  0.0015156692324042223 W =  [[1.02528127]] , b =  [0.90874892]\n",
      "step =  800 error value =  9.670865762268464e-05 W =  [[1.00638601]] , b =  [0.97695013]\n",
      "step =  1200 error value =  6.170584095286451e-06 W =  [[1.00161309]] , b =  [0.99417764]\n",
      "step =  1600 error value =  3.937197456043207e-07 W =  [[1.00040747]] , b =  [0.99852928]\n",
      "step =  2000 error value =  2.5121647429919568e-08 W =  [[1.00010292]] , b =  [0.9996285]\n",
      "step =  2400 error value =  1.6029096245043324e-09 W =  [[1.000026]] , b =  [0.99990616]\n",
      "step =  2800 error value =  1.0227511040426372e-10 W =  [[1.00000657]] , b =  [0.9999763]\n",
      "step =  3200 error value =  6.525756692793737e-12 W =  [[1.00000166]] , b =  [0.99999401]\n",
      "step =  3600 error value =  4.163818567827739e-13 W =  [[1.00000042]] , b =  [0.99999849]\n",
      "step =  4000 error value =  2.656762406327636e-14 W =  [[1.00000011]] , b =  [0.99999962]\n",
      "step =  4400 error value =  1.6951714989129112e-15 W =  [[1.00000003]] , b =  [0.9999999]\n",
      "step =  4800 error value =  1.081619667682817e-16 W =  [[1.00000001]] , b =  [0.99999998]\n",
      "step =  5200 error value =  6.901372256801365e-18 W =  [[1.]] , b =  [0.99999999]\n",
      "step =  5600 error value =  4.403481655105512e-19 W =  [[1.]] , b =  [1.]\n",
      "step =  6000 error value =  2.8096864815391533e-20 W =  [[1.]] , b =  [1.]\n",
      "step =  6400 error value =  1.792756231609357e-21 W =  [[1.]] , b =  [1.]\n",
      "step =  6800 error value =  1.1438351544691756e-22 W =  [[1.]] , b =  [1.]\n",
      "step =  7200 error value =  7.30084339551745e-24 W =  [[1.]] , b =  [1.]\n",
      "step =  7600 error value =  4.66898498997626e-25 W =  [[1.]] , b =  [1.]\n",
      "step =  8000 error value =  3.0054219982336413e-26 W =  [[1.]] , b =  [1.]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2  # 발산하는 경우, 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "for step in  range(8001):  \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4138f7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(43) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655201e",
   "metadata": {},
   "source": [
    "### 데이터 (입력 x1, x2, x3, 정답 t)에 대한 regression (multi-variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bdbda",
   "metadata": {},
   "source": [
    "##### 학습데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be62a5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 73.,  80.,  75., 152.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./data_regression.csv', delimiter=',', dtype=np.float32)\n",
    "loaded_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ed351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
      "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9d274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.9709763 ]\n",
      " [0.4445024 ]\n",
      " [0.01355926]] , W.shape =  (3, 1) , b =  [0.9267548] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(3,1)  # 3X1 행렬\n",
    "b = np.random.rand(1)  \n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1533f1c",
   "metadata": {},
   "source": [
    "##### 손실함수, 수치미분 등  simple 과 동일한 processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d85fec",
   "metadata": {},
   "source": [
    "##### 학습률 (Learning rate) 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac46a3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  2371.758133663627 Initial W =  [[0.9709763 ]\n",
      " [0.4445024 ]\n",
      " [0.01355926]] \n",
      " , b =  [0.9267548]\n",
      "step =  0 error value =  896.1281937675925 W =  [[1.04808676]\n",
      " [0.52211577]\n",
      " [0.09344957]] , b =  [0.92733801]\n",
      "step =  400 error value =  24.567648994045 W =  [[1.08864793]\n",
      " [0.59594736]\n",
      " [0.33975076]] , b =  [0.92844144]\n",
      "step =  800 error value =  20.18574638719309 W =  [[1.01715718]\n",
      " [0.55945483]\n",
      " [0.44488977]] , b =  [0.92850502]\n",
      "step =  1200 error value =  16.91715674365405 W =  [[0.95276014]\n",
      " [0.53132239]\n",
      " [0.53496655]] , b =  [0.92845195]\n",
      "step =  1600 error value =  14.464561882864835 W =  [[0.89473423]\n",
      " [0.5099583 ]\n",
      " [0.61223861]] , b =  [0.92829878]\n",
      "step =  2000 error value =  12.613128279713894 W =  [[0.84243337]\n",
      " [0.49405204]\n",
      " [0.67861431]] , b =  [0.92805958]\n",
      "step =  2400 error value =  11.20699722068106 W =  [[0.7952795 ]\n",
      " [0.48252635]\n",
      " [0.73570803]] , b =  [0.92774638]\n",
      "step =  2800 error value =  10.13259816818354 W =  [[0.75275498]\n",
      " [0.47449737]\n",
      " [0.78488642]] , b =  [0.9273694]\n",
      "step =  3200 error value =  9.306781756974832 W =  [[0.71439598]\n",
      " [0.46924145]\n",
      " [0.82730732]] , b =  [0.9269374]\n",
      "step =  3600 error value =  8.66836153161551 W =  [[0.67978663]\n",
      " [0.46616746]\n",
      " [0.86395245]] , b =  [0.92645787]\n",
      "step =  4000 error value =  8.17207009104322 W =  [[0.6485538 ]\n",
      " [0.46479386]\n",
      " [0.89565495]] , b =  [0.9259372]\n",
      "step =  4400 error value =  7.784228222416028 W =  [[0.62036255]\n",
      " [0.46472953]\n",
      " [0.92312244]] , b =  [0.92538088]\n",
      "step =  4800 error value =  7.479631700628946 W =  [[0.59491205]\n",
      " [0.46565795]\n",
      " [0.94695658]] , b =  [0.92479364]\n",
      "step =  5200 error value =  7.239305534806256 W =  [[0.57193193]\n",
      " [0.46732397]\n",
      " [0.96766938]] , b =  [0.92417952]\n",
      "step =  5600 error value =  7.048877687261802 W =  [[0.55117915]\n",
      " [0.4695229 ]\n",
      " [0.98569703]] , b =  [0.92354201]\n",
      "step =  6000 error value =  6.897396399158441 W =  [[0.53243507]\n",
      " [0.47209145]\n",
      " [1.00141156]] , b =  [0.92288411]\n",
      "step =  6400 error value =  6.7764661656403655 W =  [[0.51550298]\n",
      " [0.47490018]\n",
      " [1.0151306 ]] , b =  [0.92220842]\n",
      "step =  6800 error value =  6.679613387674614 W =  [[0.50020578]\n",
      " [0.47784736]\n",
      " [1.02712565]] , b =  [0.92151719]\n",
      "step =  7200 error value =  6.601818198387457 W =  [[0.486384  ]\n",
      " [0.48085375]\n",
      " [1.0376291 ]] , b =  [0.92081235]\n",
      "step =  7600 error value =  6.5391670187649265 W =  [[0.47389397]\n",
      " [0.48385845]\n",
      " [1.04684007]] , b =  [0.92009559]\n",
      "step =  8000 error value =  6.488593222067754 W =  [[0.46260625]\n",
      " [0.48681533]\n",
      " [1.05492942]] , b =  [0.91936837]\n",
      "step =  8400 error value =  6.447682413188511 W =  [[0.45240415]\n",
      " [0.48969021]\n",
      " [1.06204395]] , b =  [0.91863196]\n",
      "step =  8800 error value =  6.414525339658341 W =  [[0.44318245]\n",
      " [0.49245845]\n",
      " [1.06830996]] , b =  [0.91788747]\n",
      "step =  9200 error value =  6.387606107314273 W =  [[0.43484627]\n",
      " [0.49510305]\n",
      " [1.07383628]] , b =  [0.91713587]\n",
      "step =  9600 error value =  6.365716713612984 W =  [[0.42731003]\n",
      " [0.49761306]\n",
      " [1.07871678]] , b =  [0.91637799]\n",
      "step =  10000 error value =  6.347891315210169 W =  [[0.42049648]\n",
      " [0.49998225]\n",
      " [1.0830326 ]] , b =  [0.91561458]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5  # 1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "for step in  range(10001):     \n",
    "    W -= learning_rate * numerical_derivative(f, W)  \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \",b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcdbd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.68916317])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62ddf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
